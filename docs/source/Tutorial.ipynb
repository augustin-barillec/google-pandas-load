{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "## Pre-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery, storage\n",
    "from google_pandas_load import Loader, LoaderQuickSetup\n",
    "from google_pandas_load import LoadConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'dmp-y-tests'\n",
    "dataset_name = 'tmp'\n",
    "bucket_name = 'bucket_gpl'\n",
    "# gs_dir_path is the path in \n",
    "# the bucket of the directory that\n",
    "# will contain the data in Storage.  \n",
    "gs_dir_path = 'gpl_dir/subdir'\n",
    "local_dir_path = '/tmp/gpl_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(local_dir_path):\n",
    "    os.makedirs(local_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a loader\n",
    "\n",
    "Throughout this document, we call loader an instance of [google_pandas_load.Loader](Loader.rst) or of [google_pandas_load.LoaderQuickSetup](LoaderQuickSetup.rst). \n",
    "\n",
    "We emphasize that the second class is a child of the first one.\n",
    "\n",
    "The next two sections will be devoted to the creation of both classes through their main parameters which are data locations.\n",
    "\n",
    "### the low-level way\n",
    "\n",
    "To set up a loader the low-level way, use [google_pandas_load.Loader](Loader.rst).\n",
    "\n",
    "In the following code cell, credentials are inferred from the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bq_client to execute the load jobs' cloud parts, \n",
    "# which are the execution of queries, the extraction of BigQuery\n",
    "# tables to Storage and the load of tables to BigQuery \n",
    "# from Storage. \n",
    "bq_client = bigquery.Client(\n",
    "    project=project_id, \n",
    "    credentials=None)\n",
    "\n",
    "# the dataset_ref pointing to the dataset to store the data \n",
    "# in BigQuery. \n",
    "dataset_ref = bigquery.DatasetReference(\n",
    "    project=project_id, \n",
    "    dataset_id=dataset_name)\n",
    "\n",
    "# the gs_client is used to instantiate a bucket. \n",
    "gs_client = storage.Client(\n",
    "    project=project_id, \n",
    "    credentials=None)\n",
    "# the bucket to store the data in Storage. \n",
    "bucket = storage.Bucket(\n",
    "    client=gs_client, \n",
    "    name=bucket_name)\n",
    "\n",
    "gpl = Loader(\n",
    "    bq_client=bq_client,\n",
    "    dataset_ref=dataset_ref,\n",
    "    bucket=bucket,\n",
    "    gs_dir_path=gs_dir_path,\n",
    "    local_dir_path=local_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the setup above, the bq_client, the dataset_ref and the gs_client share the same project_id. Furthermore, the bq_client and the gs_client share the same credentials. However neither the project_id nor the credentials are required to be the same.\n",
    "\n",
    "In order to be able to execute load jobs with all possible source and destination, the bq_client must have read and write access in both the dataset and the bucket.\n",
    "\n",
    "If one wants to use directly the bucketâ€™s root directory to store the data loaded in Storage, one can set the gs_dir_path parameter to None.\n",
    "\n",
    "### the quick way\n",
    "\n",
    "To set up a loader quickly, use [google_pandas_load.LoaderQuickSetup](LoaderQuickSetup.rst).\n",
    "\n",
    "The code behind the instantiation is essentially the same as in the previous cell.\n",
    "\n",
    "Contrary to the low-level way the bq_client, the dataset_ref and the gs_client share the same project_id. Moreover the bq_client and the gs_client share the same credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl_quick_setup = LoaderQuickSetup(\n",
    "    project_id=project_id, \n",
    "    dataset_name=dataset_name, \n",
    "    bucket_name=bucket_name, \n",
    "    gs_dir_path=gs_dir_path,\n",
    "    credentials=None,\n",
    "    local_dir_path=local_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x\n",
       "0  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gpl.load(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 1 as x')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='dataframe', \n",
    "    destination='bq',\n",
    "    data_name='a0',\n",
    "    dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command has created the following table in BigQuery:\n",
    "\n",
    "![](a0_in_bq.png)\n",
    "\n",
    "Its id in BigQuery is project_id:dataset_name.a0, where project_id is the dataset's one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic loading mechanism\n",
    "\n",
    "It is explained in the documentation of this method [google_pandas_load.Loader.load()](Loader.rst#google_pandas_load.loader.Loader.load). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples\n",
    "\n",
    "\n",
    "### from query to gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='query', \n",
    "    destination='gs', \n",
    "    data_name='a0',\n",
    "    query='select 5 as y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from gs to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='gs', \n",
    "    destination='local', \n",
    "    data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from local to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpl.load(\n",
    "    source='local', \n",
    "    destination='dataframe', \n",
    "    data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from dataframe to gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='dataframe', \n",
    "    destination='gs', \n",
    "    data_name='a0', \n",
    "    dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from gs to bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='gs', \n",
    "    destination='bq', \n",
    "    data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from \n",
    "(select 'Hello, ' as x from unnest(generate_array(1, 4000))) \n",
    "cross join \n",
    "(select 'World!' as y from unnest(generate_array(1, 4000)))\n",
    "\"\"\"\n",
    "\n",
    "gpl.load(\n",
    "    source='query', \n",
    "    destination='gs',\n",
    "    data_name='a0',\n",
    "    query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list this data, [named](Loader.html#named) a0, in Storage:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: bucket_gpl, gpl_dir/subdir/a0-000000000000.csv.gz, 1609341733792610>,\n",
       " <Blob: bucket_gpl, gpl_dir/subdir/a0-000000000001.csv.gz, 1609341734022325>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl.list_blobs(data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to list the blob uris: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://bucket_gpl/gpl_dir/subdir/a0-000000000000.csv.gz',\n",
       " 'gs://bucket_gpl/gpl_dir/subdir/a0-000000000001.csv.gz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl.list_blob_uris(data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, data turned out to be sufficiently large that BigQuery had to split it into several files in Storage.\n",
    "\n",
    "Let us move this data into the local folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpl.load(\n",
    "    source='gs', \n",
    "    destination='local',\n",
    "    data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list this data, [named](Loader.html#named) a0, in the local folder:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/gpl_directory/a0-000000000001.csv.gz',\n",
       " '/tmp/gpl_directory/a0-000000000000.csv.gz']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpl.list_local_file_paths(data_name='a0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent BigQuery from splitting the data, set use_wildcard to False when creating the loader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(gpl.exist_in_local(data_name='a1'))\n",
    "\n",
    "gpl.load(\n",
    "    source='query', \n",
    "    destination='local',\n",
    "    data_name='a1',\n",
    "    query='select 2')\n",
    "\n",
    "print(gpl.exist_in_local(data_name='a1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "gpl.load(\n",
    "    source='query', \n",
    "    destination='gs',\n",
    "    data_name='a1',\n",
    "    query='select 2')\n",
    "\n",
    "print(gpl.exist_in_gs(data_name='a1'))\n",
    "gpl.delete_in_gs(data_name='a1')\n",
    "print(gpl.exist_in_gs(data_name='a1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast data\n",
    "\n",
    "### cast data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x    y  z\n",
       "0  5  5.0  5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select 5 as x, 5 as y, 5 as z\n",
    "\"\"\"\n",
    "dtype = {\n",
    "    'x': str, \n",
    "    'y': float}\n",
    "\n",
    "df = gpl.load(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query=query, \n",
    "    dtype=dtype)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x     object\n",
       "y    float64\n",
       "z      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cast a column into the datetime.datetime type, use the parse_dates parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-14 14:32:30+00:00</td>\n",
       "      <td>2013-11-14 14:32:30.100121</td>\n",
       "      <td>2012-11-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          x                          y          z\n",
       "0 2012-11-14 14:32:30+00:00 2013-11-14 14:32:30.100121 2012-11-14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select \n",
    "cast('2012-11-14 14:32:30' as TIMESTAMP) as x, \n",
    "'2013-11-14 14:32:30.100121' as y,\n",
    "'2012-11-14' as z\n",
    "\"\"\"\n",
    "\n",
    "df = gpl.load(\n",
    "    source='query',\n",
    "    destination='dataframe',\n",
    "    query=query,\n",
    "    parse_dates=['x', 'y', 'z'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    datetime64[ns, UTC]\n",
       "y         datetime64[ns]\n",
       "z         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cast data into BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes the schema of the BigQuery table when destination = 'bq'. \n",
    "\n",
    "If source = 'query', the bq_schema argument is ignored. The bq_schema is inferred from the query.\n",
    "\n",
    "Otherwise, one can use this argument to provide an explicit schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaField('x', 'FLOAT', 'NULLABLE', None, (), None),\n",
       " SchemaField('y', 'STRING', 'NULLABLE', None, (), None)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame(data={'x': [7, 8], 'y': ['a', 'b']})\n",
    "\n",
    "gpl.load(\n",
    "    source='dataframe', \n",
    "    destination='gs', \n",
    "    data_name='a0', \n",
    "    dataframe=df)\n",
    "\n",
    "\n",
    "bq_schema = [bigquery.SchemaField(name='x', field_type='FLOAT'),\n",
    "             bigquery.SchemaField(name='y', field_type='STRING')]\n",
    "\n",
    "gpl.load(\n",
    "    source='gs', \n",
    "    destination='bq', \n",
    "    data_name='a0', \n",
    "    bq_schema=bq_schema)\n",
    "\n",
    "table_ref = dataset_ref.table(table_id='a0')\n",
    "table = bq_client.get_table(table_ref)\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If source is one of 'gs' or 'local' and the bq_schema is not passed, it falls back to an inferred value from the CSV with [google.cloud.bigquery.job.LoadJobConfig.autodetect](https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.LoadJobConfig.html#google.cloud.bigquery.job.LoadJobConfig). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaField('x', 'INTEGER', 'NULLABLE', None, (), None),\n",
       " SchemaField('y', 'STRING', 'NULLABLE', None, (), None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame(data={'x': [7, 8], 'y': ['a', 'b']})\n",
    "\n",
    "gpl.load(\n",
    "    source='dataframe', \n",
    "    destination='gs', \n",
    "    data_name='a0', \n",
    "    dataframe=df)\n",
    "\n",
    "gpl.load(\n",
    "    source='gs', \n",
    "    destination='bq', \n",
    "    data_name='a0')\n",
    "\n",
    "table_ref = dataset_ref.table(table_id='a0')\n",
    "table = bq_client.get_table(table_ref)\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If source = 'dataframe' and the bq_schema is not passed, it falls back to an inferred value from the dataframe with [google_pandas_load.load_config.LoadConfig.bq_schema_inferred_from_dataframe](LoadConfig.rst#google_pandas_load.load_config.LoadConfig.bq_schema_inferred_from_dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaField('w', 'FLOAT', 'NULLABLE', None, (), None),\n",
       " SchemaField('x', 'STRING', 'NULLABLE', None, (), None),\n",
       " SchemaField('y', 'DATE', 'NULLABLE', None, (), None),\n",
       " SchemaField('z', 'TIMESTAMP', 'NULLABLE', None, (), None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = datetime.strptime(\n",
    "    '2003-11-14 14:32:30.100121', \n",
    "    '%Y-%m-%d %H:%M:%S.%f')\n",
    "df = pandas.DataFrame(\n",
    "    data={\n",
    "        'w': [8.0], \n",
    "        'x': ['e'], \n",
    "        'y': ['2018-01-01'], \n",
    "        'z': [dt]})\n",
    "\n",
    "gpl.load(\n",
    "    source='dataframe', \n",
    "    destination='bq', \n",
    "    data_name='a0', \n",
    "    dataframe=df, \n",
    "    date_cols=['y'], \n",
    "    timestamp_cols=['z'])\n",
    "\n",
    "table_ref = dataset_ref.table(table_id='a0')\n",
    "table = bq_client.get_table(table_ref)\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = LoadConfig(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 1 as x')\n",
    "\n",
    "\n",
    "df = pandas.DataFrame(data={'x': [3]})\n",
    "config2 = LoadConfig(\n",
    "    source='dataframe', \n",
    "    destination='local', \n",
    "    data_name='a0',\n",
    "    dataframe=df)\n",
    "\n",
    "load_results = gpl.mload(configs=[config1, config2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x\n",
       "0  1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(load_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monitor a load job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xload_result = gpl.xload(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 11 as x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x\n",
       "0  11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xload_result.load_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201230162302_788202_rand225922070347300551339609047975090589538\n",
      "2\n",
      "Namespace(bq_to_gs=1, dataframe_to_local=None, gs_to_bq=None, gs_to_local=0, local_to_dataframe=0, local_to_gs=None, query_to_bq=1)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(xload_result.data_name)\n",
    "print(xload_result.duration)\n",
    "print(xload_result.durations)\n",
    "print(xload_result.query_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monitor a multi load job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = LoadConfig(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 1 as x')\n",
    "\n",
    "\n",
    "df = pandas.DataFrame(data={'x': [3]})\n",
    "config2 = LoadConfig(\n",
    "    source='dataframe', \n",
    "    destination='local', \n",
    "    data_name='a0',\n",
    "    dataframe=df)\n",
    "\n",
    "xmload_result = gpl.xmload(configs=[config1, config2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   x\n",
       " 0  1,\n",
       " None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmload_result.load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20201230162306_494049_rand155165725803913463411590889255423149244', 'a0']\n",
      "2\n",
      "Namespace(bq_to_gs=1, dataframe_to_local=0, gs_to_bq=None, gs_to_local=0, local_to_dataframe=0, local_to_gs=None, query_to_bq=1)\n",
      "0.0\n",
      "[0.0, None]\n"
     ]
    }
   ],
   "source": [
    "print(xmload_result.data_names)\n",
    "print(xmload_result.duration)\n",
    "print(xmload_result.durations)\n",
    "print(xmload_result.query_cost)\n",
    "print(xmload_result.query_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logger creating [google_pandas_load.Loader](Loader.rst)'s log records is named Loader and is controlled, as usual, by the application code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('Loader')\n",
    "logger.setLevel(level=logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(fmt='%(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(fmt=formatter)\n",
    "logger.addHandler(hdlr=ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loader - DEBUG - Starting query to bq...\n",
      "Loader - DEBUG - Ended query to bq [1s, 0.0$]\n",
      "Loader - DEBUG - Starting bq to gs...\n",
      "Loader - DEBUG - Ended bq to gs [1s]\n",
      "Loader - DEBUG - Starting gs to local...\n",
      "Loader - DEBUG - Ended gs to local [0s]\n",
      "Loader - DEBUG - Starting local to dataframe...\n",
      "Loader - DEBUG - Ended local to dataframe [0s]\n"
     ]
    }
   ],
   "source": [
    "df = gpl.load(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 1 as x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logger creating [google_pandas_load.LoaderQuickSetup](LoaderQuickSetup.rst)'s log records is named LoaderQuickSetup. Contrary to the logger Loader, it already has a built-in console handler. Therefore, without any logging set up, logging records are displayed in the console. This is convenient when working with notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-30 16:23:13,594 - LoaderQuickSetup - DEBUG - Starting query to bq...\n",
      "2020-12-30 16:23:15,080 - LoaderQuickSetup - DEBUG - Ended query to bq [1s, 0.0$]\n",
      "2020-12-30 16:23:15,082 - LoaderQuickSetup - DEBUG - Starting bq to gs...\n",
      "2020-12-30 16:23:17,242 - LoaderQuickSetup - DEBUG - Ended bq to gs [2s]\n",
      "2020-12-30 16:23:17,243 - LoaderQuickSetup - DEBUG - Starting gs to local...\n",
      "2020-12-30 16:23:17,511 - LoaderQuickSetup - DEBUG - Ended gs to local [0s]\n",
      "2020-12-30 16:23:17,513 - LoaderQuickSetup - DEBUG - Starting local to dataframe...\n",
      "2020-12-30 16:23:17,525 - LoaderQuickSetup - DEBUG - Ended local to dataframe [0s]\n"
     ]
    }
   ],
   "source": [
    "df = gpl_quick_setup.load(\n",
    "    source='query', \n",
    "    destination='dataframe', \n",
    "    query='select 1 as x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid duplicate log records in the console, the LoaderQuickSetup logger is by default set to not propagate its log records to its logger ancestors. \n",
    "\n",
    "Both [google_pandas_load.Loader](Loader.rst) and [google_pandas_load.LoaderQuickSetup](LoaderQuickSetup.rst) have a logger parmeter. The default values are respectively the Loader logger and the LoaderQuickSetup logger. The parameters can, in both cases, be replaced by another logger. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
